{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Define paths\n",
    "notebooks_path = os.path.abspath(os.getcwd()) \n",
    "src_path = os.path.abspath(os.path.join(notebooks_path, \"../src\"))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your custom functions (including the markovian solvers)\n",
    "from optimal_code.utils import *\n",
    "from optimal_code.optimal_solver import *\n",
    "from optimal_code.optimal_solver_markov import *\n",
    "\n",
    "from trees.build_trees_from_paths import *\n",
    "\n",
    "# Import modules\n",
    "from trees.multi_dimension.Multidimension_trees import *\n",
    "from trees.multi_dimension.Multidimension_solver import *\n",
    "from trees.multi_dimension.Multidimension_adapted_empirical_measure import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from trees.tree_Node import *\n",
    "from trees.treeAnalysis import *\n",
    "from trees.treeVisualization import *\n",
    "from trees.tree_AWD_utilities import *\n",
    "from trees.build_trees_from_paths import build_tree_from_paths\n",
    "\n",
    "from trees.awd_trees.Discrete_OT_Solver_algo import *\n",
    "from trees.awd_trees.Gurobi_AOT import *\n",
    "from trees.awd_trees.Nested_Dist_Algo import *\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapted_empirical_measure.AEM_grid import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark_value_gaussian.Comp_AWD2_Gaussian import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Paths for d=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization flag\n",
    "normalize = False\n",
    "\n",
    "# Define factor matrices\n",
    "L0 = np.array([[1, 0, 0, 0], [1, 2, 0, 0], [1, 2, 3, 0], [1,2,3, 4]])\n",
    "A0 = L0 @ L0.T\n",
    "L = L0 / np.sqrt(np.trace(A0)) if normalize else L0\n",
    "A = L @ L.T\n",
    "\n",
    "M0 = np.array([[1, 0, 0, 0], [2, 1, 0, 0], [3, 2, 1, 0], [4, 3, 2, 1]])\n",
    "B0 = M0 @ M0.T\n",
    "M = M0 / np.sqrt(np.trace(B0)) if normalize else M0\n",
    "B = M @ M.T\n",
    "\n",
    "# Parameters\n",
    "d = 1\n",
    "T = 4\n",
    "dim = d * T\n",
    "n_sample_plot = 100\n",
    "\n",
    "# Generate all noise samples at once\n",
    "noise1 = np.random.normal(size=(n_sample_plot, dim))\n",
    "noise2 = np.random.normal(size=(n_sample_plot, dim))\n",
    "\n",
    "# Apply transformations\n",
    "X_increments = (noise1 @ L.T).reshape(n_sample_plot, T, d)\n",
    "Y_increments = (noise2 @ M.T).reshape(n_sample_plot, T, d)\n",
    "\n",
    "# Prepend zeros along the time axis\n",
    "X_paths = np.concatenate([np.zeros((n_sample_plot, 1, d)), X_increments], axis=1)\n",
    "Y_paths = np.concatenate([np.zeros((n_sample_plot, 1, d)), Y_increments], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Nested Distance (Multi-Dimensional Framework for $\\mathbb{R}^{1\\cdot T}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt empirical measures\n",
    "adapted_X, adapted_weights_X = multidim_uniform_empirical_grid_measure(X_paths, use_weights=True)\n",
    "adapted_Y, adapted_weights_Y = multidim_uniform_empirical_grid_measure(Y_paths, use_weights=True)\n",
    "\n",
    "# Build trees\n",
    "adapted_tree_1 = multidim_build_tree_from_paths(adapted_X, adapted_weights_X)\n",
    "adapted_tree_2 = multidim_build_tree_from_paths(adapted_Y, adapted_weights_Y)\n",
    "\n",
    "# Compute nested distance\n",
    "max_depth = multidim_get_depth(adapted_tree_1)\n",
    "start_time = time.time()\n",
    "distance_pot = multidim_compute_nested_distance(adapted_tree_1, adapted_tree_2, max_depth, power=2)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Nested distance multi dim:\", distance_pot)\n",
    "print(\"Computation time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Nested Distance (Original Code for $\\mathbb{R}^{T}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt empirical measures\n",
    "X, Y = np.squeeze(X_paths, axis=-1), np.squeeze(Y_paths, axis=-1)\n",
    "adapted_X, adapted_weights_X = uniform_empirical_grid_measure(X, use_weights=True)\n",
    "adapted_Y, adapted_weights_Y = uniform_empirical_grid_measure(Y, use_weights=True)\n",
    "\n",
    "# Build trees\n",
    "adapted_tree_1 = build_tree_from_paths(adapted_X, adapted_weights_X)\n",
    "adapted_tree_2 = build_tree_from_paths(adapted_Y, adapted_weights_Y)\n",
    "\n",
    "# Compute nested distance\n",
    "max_depth = get_depth(adapted_tree_1)\n",
    "start_time = time.time()\n",
    "distance_pot = compute_nested_distance_parallel(adapted_tree_1, adapted_tree_2, max_depth, power=2)\n",
    "elapsed_time_pot = time.time() - start_time\n",
    "\n",
    "print(\"Nested distance single dim:\", distance_pot)\n",
    "print(\"Computation time: {:.4f} seconds\".format(elapsed_time_pot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theoretical Nested Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.zeros(dim), np.zeros(dim)\n",
    "distance_aw2 = adapted_wasserstein_squared_multidim(a, A, b, B, d, T)\n",
    "\n",
    "print(\"Adapted Wasserstein Squared Distance for custom Gaussian process:\", distance_aw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For d = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "d = 2\n",
    "T = 2\n",
    "dim = d * T\n",
    "n_sample_plot = 100\n",
    "\n",
    "# Generate all noise samples at once\n",
    "noise1 = np.random.normal(size=(n_sample_plot, dim))\n",
    "noise2 = np.random.normal(size=(n_sample_plot, dim))\n",
    "\n",
    "# Apply transformations\n",
    "X_increments = (noise1 @ L.T).reshape(n_sample_plot, T, d)\n",
    "Y_increments = (noise2 @ M.T).reshape(n_sample_plot, T, d)\n",
    "\n",
    "# Prepend zeros along the time axis\n",
    "X_paths = np.concatenate([np.zeros((n_sample_plot, 1, d)), X_increments], axis=1)\n",
    "Y_paths = np.concatenate([np.zeros((n_sample_plot, 1, d)), Y_increments], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt empirical measures\n",
    "adapted_X, adapted_weights_X = multidim_uniform_empirical_grid_measure(X_paths, use_weights=True)\n",
    "adapted_Y, adapted_weights_Y = multidim_uniform_empirical_grid_measure(Y_paths, use_weights=True)\n",
    "\n",
    "# Build trees\n",
    "adapted_tree_1 = multidim_build_tree_from_paths(adapted_X, adapted_weights_X)\n",
    "adapted_tree_2 = multidim_build_tree_from_paths(adapted_Y, adapted_weights_Y)\n",
    "\n",
    "# Compute nested distance\n",
    "max_depth = multidim_get_depth(adapted_tree_1)\n",
    "start_time = time.time()\n",
    "distance_pot = multidim_nested_optimal_transport_loop_parallel(adapted_tree_1, adapted_tree_2, max_depth, power=2, n_processes= 1)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Nested distance multi dim:\", distance_pot)\n",
    "print(\"Computation time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt empirical measures\n",
    "adapted_X, adapted_weights_X = multidim_empirical_k_means_measure_new(X_paths, use_weights=True)\n",
    "adapted_Y, adapted_weights_Y = multidim_empirical_k_means_measure_new(Y_paths, use_weights=True)\n",
    "\n",
    "# Build trees\n",
    "adapted_tree_1 = multidim_build_tree_from_paths(adapted_X, adapted_weights_X)\n",
    "adapted_tree_2 = multidim_build_tree_from_paths(adapted_Y, adapted_weights_Y)\n",
    "\n",
    "# Compute nested distance\n",
    "max_depth = multidim_get_depth(adapted_tree_1)\n",
    "start_time = time.time()\n",
    "distance_pot = multidim_nested_optimal_transport_loop_parallel(adapted_tree_1, adapted_tree_2, max_depth, power=2, n_processes= 1)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Nested distance multi dim:\", distance_pot)\n",
    "print(\"Computation time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.zeros(dim), np.zeros(dim)\n",
    "distance_aw2 = adapted_wasserstein_squared_multidim(a, A, b, B, d, T)\n",
    "\n",
    "print(\"Adapted Wasserstein Squared Distance for custom Gaussian process:\", distance_aw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing my implementation vs the other implentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_code.utils_multidim import *\n",
    "from optimal_code.optimal_solver_multidim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m n_sample_plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m150\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Example transformation matrices (L and M) of shape (dim, dim)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Here we simply use random matrices for illustration\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Generate noise and compute paths\u001b[39;00m\n\u001b[1;32m     12\u001b[0m X, A \u001b[38;5;241m=\u001b[39m Lmatrix2paths_flat(L, n_sample_plot, d, T, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "d = 2\n",
    "T = 2\n",
    "dim = d * T\n",
    "n_sample_plot = 150\n",
    "\n",
    "# Example transformation matrices (L and M) of shape (dim, dim)\n",
    "# Here we simply use random matrices for illustration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate noise and compute paths\n",
    "X, A = Lmatrix2paths_flat(L, n_sample_plot, d, T, seed=1, verbose=True)\n",
    "Y, B = Lmatrix2paths_flat(M, n_sample_plot, d, T, seed=1, verbose=True)\n",
    "\n",
    "print(\"X_paths shape:\", X_paths.shape)\n",
    "print(\"Y_paths shape:\", Y_paths.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapted Wasserstein Squared Distance for custom Gaussian process: 22.02336710106509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [00:00<00:00, 141.05it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 141.68it/s]\n",
      "100%|██████████| 115/115 [00:00<00:00, 134.70it/s]\n",
      "100%|██████████| 114/114 [00:00<00:00, 127.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.34it/s]\n"
     ]
    }
   ],
   "source": [
    "a, b = np.zeros(dim), np.zeros(dim)\n",
    "distance_aw2 = adapted_wasserstein_squared_multidim(a, A, b, B, d, T)\n",
    "\n",
    "print(\"Adapted Wasserstein Squared Distance for custom Gaussian process:\", distance_aw2)\n",
    "\n",
    "fixed_grid = 0.1\n",
    "\n",
    "# Project paths onto the fixed grid (applied elementwise)\n",
    "adaptedX = path2adaptedpath_multidim(X, delta_n=fixed_grid)\n",
    "adaptedY = path2adaptedpath_multidim(Y, delta_n=fixed_grid)\n",
    "\n",
    "# Build quantization mapping:\n",
    "# Reshape the data so that we obtain a list of all ℝ² points:\n",
    "# adaptedX: shape (T+1, n_sample, d) -> (n_sample, T+1, d)\n",
    "points_X = adaptedX.transpose(1,0,2).reshape(-1, d)\n",
    "points_Y = adaptedY.transpose(1,0,2).reshape(-1, d)\n",
    "# Use np.unique along axis=0 to get unique grid points in ℝ².\n",
    "q2v = np.unique(np.concatenate([points_X, points_Y], axis=0), axis=0)\n",
    "# Convert each unique row (a 2D vector) to a tuple so it can be used as a key.\n",
    "q2v_list = [tuple(row) for row in q2v]\n",
    "v2q = {val: i for i, val in enumerate(q2v_list)}\n",
    "\n",
    "# Quantize each path: iterate over sample paths.\n",
    "# Resulting qX will have shape (n_sample, T+1) with integer entries.\n",
    "qX = np.array([[v2q[tuple(x)] for x in sample] \n",
    "                for sample in adaptedX.transpose(1,0,2)])\n",
    "qY = np.array([[v2q[tuple(x)] for x in sample] \n",
    "                for sample in adaptedY.transpose(1,0,2)])\n",
    "\n",
    "# Sort the quantized paths lexicographically (as in your 1D code)\n",
    "qX = sort_qpath_multidim(qX.T)\n",
    "qY = sort_qpath_multidim(qY.T)\n",
    "\n",
    "# Build conditional distributions from the quantized paths.\n",
    "mu_x = qpath2mu_x_multidim(qX)\n",
    "nu_y = qpath2mu_x_multidim(qY)\n",
    "mu_x_c, mu_x_cn, mu_x_v, mu_x_w, mu_x_cumn = list_repr_mu_x_multidim(mu_x, q2v)\n",
    "nu_y_c, nu_y_cn, nu_y_v, nu_y_w, nu_y_cumn = list_repr_mu_x_multidim(nu_y, q2v)\n",
    "\n",
    "# Compute the numerical adapted Wasserstein squared distance.\n",
    "t_start = time.perf_counter()\n",
    "AW_2square = nested2_parallel_multidim(mu_x_cn, mu_x_v, mu_x_w, mu_x_cumn,\n",
    "                                nu_y_cn, nu_y_v, nu_y_w, nu_y_cumn,\n",
    "                                n_processes=4, power=2)\n",
    "elapsed = time.perf_counter() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.172473333333329\n"
     ]
    }
   ],
   "source": [
    "print(AW_2square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Depth 1:  11%|█         | 20209/191902 [08:24<1:10:00, 40.87pair/s]Process SpawnProcess-24:\n",
      "Process SpawnProcess-23:\n",
      "Process SpawnProcess-22:\n",
      "Process SpawnProcess-25:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Depth 1:  11%|█         | 20210/191902 [08:24<1:11:24, 40.07pair/s]\n"
     ]
    }
   ],
   "source": [
    "# Adapt empirical measures\n",
    "adapted_X, adapted_weights_X = multidim_uniform_empirical_grid_measure(X, delta_n= fixed_grid, use_weights=True)\n",
    "adapted_Y, adapted_weights_Y = multidim_uniform_empirical_grid_measure(Y, delta_n= fixed_grid,  use_weights=True)\n",
    "\n",
    "# Build trees\n",
    "adapted_tree_1 = multidim_build_tree_from_paths(adapted_X, adapted_weights_X)\n",
    "adapted_tree_2 = multidim_build_tree_from_paths(adapted_Y, adapted_weights_Y)\n",
    "\n",
    "# Compute nested distance\n",
    "max_depth = multidim_get_depth(adapted_tree_1)\n",
    "start_time = time.time()\n",
    "distance_pot = multidim_nested_optimal_transport_loop_parallel(adapted_tree_1, adapted_tree_2, max_depth, power=2, n_processes= 4)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Nested distance multi dim:\", distance_pot)\n",
    "print(\"Computation time: {:.4f} seconds\".format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
